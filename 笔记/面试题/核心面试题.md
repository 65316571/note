# Java

### ⭐接口和抽象类的区别是什么？

1. 接口的方法默认是public，所有方法在接口中不能有实现(Java8开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。
2. 接口中除了static、final变量，不能有其他变量，而抽象类中则不一定。
3. 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过extends关键字扩展多个接口。
4. 接口方法默认修饰符是public，抽象方法可以有public、protected和default这些修饰符（抽象方法就是为了被重写所以不能使用private关键字修饰！）。
5. 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。



### ⭐== 与 equals的区别

对于**基本类型**来说，== 比较的是值是否相等；

对于**引用类型**来说，== 比较的是两个引用是否指向同一个对象地址（两者在内存中存放的地址（堆内存地址）是否指向同一个地方）；

equals ：用来比较两个对象的内容是否相等。注意：equals 方法不能用于比较基本数据类型的变量。如果没有对 equals 方法进行重写，则比较的是引用类型的变量所指向的对象的地址（很多类重写了 equals 方法，比如 String、Integer 等把它变成了值比较，所以一般情况下 equals 比较的是值是否相等）



### ⭐Java集合类框架的基本接口有哪些？

Java中的集合分为value（Conllection），key-value(Map)两种存储结构

> 存储value有分为List 、Set、Queue

List：有序，可存储重复元素

Set：无序，元素不可重复。根据equals和hashcode判断（如果一个对象要存储在Set中，必须重写equals和hashCode方法）

Queue：队列

> 存储key-value的为map

![image-20220609215207876](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220609215207876-1ee5a9ab.webp)image-20220609215207876

![image-20220609215218381](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220609215218381-c43ca871.webp)image-20220609215218381

![image-20220609215224938](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220609215224938-9836865f.webp)image-20220609215224938

### ⭐ Arraylist 与 LinkedList 区别

1. **是否保证线程安全**： ArrayList 和 LinkedList 都是不同步的，也就是不保证线程安全；
2. **底层数据结构**： Arraylist 底层使用的是 Object 数组； LinkedList 底层使用的是 双向链表数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
3. **插入和删除是否受元素位置的影响**：①ArrayList采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。比如：执行add(Ee)方法的时候，ArrayList会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置i插入和删除元素的话（add(intindex,Eelement)）时间复杂度就为O(n-i)。因为在进行上述操作的时候集合中第i和第i个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。②LinkedList采用链表存储，所以对于add(Ee)方法的插入，删除元素时间复杂度不受元素位置的影响，近似O(1)，如果是要在指定位置i插入和删除元素的话（(add(intindex,Eelement)）时间复杂度近似为o(n))因为需要先移动到指定位置再插入。
4. **是否支持快速随机访问**：LinkedList不支持高效的随机元素访问，而ArrayList支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(intindex)方法)。
5. **内存空间占用**：ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）。

### ⭐JVM虚拟机架构图（建议背诵）![image-20220629110459744](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220629110459744-b785bed5.webp)

# Spring

### ⭐️ Spring中都有哪些设计模式？

> 概述

1、**简单工厂模式**：`BeanFactory`就是简单工厂模式的体现，根据传入一个唯一标识来获得 Bean 对象。在Spring Boot中具体实现的类是`AnnotationConfigApplicationContext`。

2、**工厂方法模式**：`FactoryBean`就是典型的工厂方法模式。spring在使用`getBean()`调用获得该bean时，会自动调用该bean的`getObject()`方法。每个 Bean 都会对应一个 `FactoryBean`，如 `SqlSessionFactory` 对应 `SqlSessionFactoryBean`。

3、**单例模式**：一个类仅有一个实例，提供一个访问它的全局访问点。Spring 创建 Bean 实例默认是单例的。

4、**适配器模式**：SpringMVC中的适配器`HandlerAdatper`。这个`HandlerAdatper`的理解有点复杂，具体来说是将不同的Handler(比如Controller)适配转换为DispatcherServlet可以调用的handle方法。比如现在有一个controller叫作SimpleController，就可以通过SimpleControllerHandlerAdapter的handle方法将它转换成可以被DispatcherServlet识别的方法，这样就可以请求来了 -> DispatcherServlet找适配器 -> 找到SimpleControllerHandlerAdapter -> 调用它的handle方法 -> handle方法内部调用SimpleController的handleRequest方法 -> 最后将结果返回给DispatcherServlet。同样的，如果有一个PigController，就使用PigControllerHandlerAdapter将其转换成DispatcherServlet可以调用的接口。

```java
public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) {
    ((SimpleController) handler).handleRequest(request, response);
    // 返回ModelAndView
}
```

5、**代理模式**：spring 的 Aop 使用了动态代理，有两种方式`JdkDynamicAopProxy`和`Cglib2AopProxy`。

6、**观察者模式**：spring 中 observer 模式常用的地方是 listener 的实现，如`ApplicationListener`。

7、**模板模式**： Spring 中 `jdbcTemplate`、`hibernateTemplate` 等，就使用到了模板模式。

[完整介绍：Spring的设计模式](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/Java/eightpart/spring.html#⭐️-spring中都有哪些设计模式-2022热门问题)



### 🌟 Spring Bean 生命周期

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/20220709213529-fec64dd0.webp)img

首先简要介绍 Spring Bean 和 Spring IoC（控制反转）容器的基本概念。

Spring Bean 是 Spring 框架中的一个基本组成部分，它们是由 Spring IoC 容器管理的 Java 对象。Spring Bean 生命周期描述了从对象创建到销毁的整个过程，这个过程由容器管理并通过各种回调方法来执行。

**生命周期阶段**：详细介绍 Spring Bean 生命周期的各个阶段。

- 实例化（Instantiation）：Spring IoC 容器创建 Bean 实例。
- 属性赋值（Populate properties）：容器根据 Bean 定义的依赖关系，为 Bean 的属性赋值。
- 初始化（Initialization）：Bean 初始化的几个步骤：
  - 如果 Bean 实现了 `BeanNameAware` 接口，容器会调用 `setBeanName()` 方法传入 Bean 的名称。
  - 如果 Bean 实现了 `BeanFactoryAware` 接口，容器会调用 `setBeanFactory()` 方法传入 Bean 工厂。
  - 如果 Bean 实现了 `ApplicationContextAware` 接口，容器会调用 `setApplicationContext()` 方法传入应用上下文。
  - 如果 Bean 配置了 `BeanPostProcessor`，则在初始化前后调用 `postProcessBeforeInitialization()` 和 `postProcessAfterInitialization()` 方法。
  - 如果 Bean 实现了 `InitializingBean` 接口，容器会调用 `afterPropertiesSet()` 方法。
  - 如果 Bean 配置了自定义的初始化方法，容器会调用该方法。
- 销毁（Destruction）：Bean 销毁的几个步骤：
  - 如果 Bean 实现了 `DisposableBean` 接口，容器会调用 `destroy()` 方法。
  - 如果 Bean 配置了自定义的销毁方法，容器会调用该方法。



### 🌟 Spring MVC的工作流程？

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/de6d2b213f112297298f3e223bf08f28-be1aeda6.webp)

1. 客户端（浏览器）发送请求， `DispatcherServlet`拦截请求。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping` 。`HandlerMapping` 根据 uri 去匹配查找能处理的 `Handler`（也就是我们平常说的 `Controller` 控制器） ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
3. `DispatcherServlet` 调用 `HandlerAdapter`适配器执行 `Handler` 。
4. `Handler` 完成对用户请求的处理后，会返回一个 `ModelAndView` 对象给`DispatcherServlet`，`ModelAndView` 顾名思义，包含了数据模型以及相应的视图的信息。`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
5. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
6. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
7. 把 `View` 返回给请求者（浏览器）

# MSQL 

### ⭐MyISAM和InnoDB 的区别是什么？

除了6，都是InnoDB支持，前者不支持

**1.是否支持行级锁**

**2.是否支持事务**

**3.是否支持外键**

**4.是否支持数据库异常崩溃后的安全恢复**

> MyISAM 不支持，而 InnoDB 支持。
>
> 使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 `redo log` 。

**5.是否支持 MVCC**

**6.索引实现不一样。**

> 虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。
>
> InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。



### ⭐️聚簇索引和非聚簇索引

> 简洁回答

- 一个表中只能拥有一个聚集索引，而非聚集索引一个表可以存在多个。
- 索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。
- 聚集索引：物理存储按照索引排序；非聚集索引：物理存储不按照索引排序

> 详细

另外，索引又可以分成聚簇索引和非聚簇索引（二级索引），它们区别就在于叶子节点存放的是什么数据：

- 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；
- 二级索引的叶子节点存放的是主键值，而不是实际数据。

因为表的数据都是存放在聚簇索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个。

InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：

- 如果有主键，默认会使用主键作为聚簇索引的索引键；
- 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；
- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；

一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引/辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。

二级索引的 B+ 树如下图，数据部分为主键值：

![image-20220718134133927](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220718134133927-0798d21d.webp)image-20220718134133927

因此，**如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据。



### ⭐数据库事务？

简单来说，数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。构成这个逻辑上的整体的这些数据库操作遵循：**要么全部执行成功,要么全部不执行** 。



```sql
# 开启一个事务
START TRANSACTION;
# 多条 SQL 语句
SQL1,SQL2...
## 提交事务
COMMIT;
```

![image-20220613143832546](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220613143832546-7a3eb484.webp)image-20220613143832546

另外，关系型数据库（例如：`MySQL`、`SQL Server`、`Oracle` 等）事务都有 **ACID** 特性：

![image-20220613143851071](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220613143851071-2b4a3eac.webp)image-20220613143851071

1. **原子性**（`Atomicity`） ： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性**（`Consistency`）： 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
3. **隔离性**（`Isolation`）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性**（`Durabilily`）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

🌈 这里要额外补充一点：**只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！** 想必大家也和我一样，被 ACID 这个概念被误导了很久!

![image-20220613144017540](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220613144017540-3b8d3d5e.webp)image-20220613144017540

另外，DDIA 也就是 [《Designing Data-Intensive Application（数据密集型应用系统设计）》open in new window](https://book.douban.com/subject/30329536/)

的作者在他的这本书中如是说：

> Atomicity, isolation, and durability are properties of the database, whereas consis‐ tency (in the ACID sense) is a property of the application. The application may rely on the database’s atomicity and isolation properties in order to achieve consistency, but it’s not up to the database alone.
>
> 翻译过来的意思是：原子性，隔离性和持久性是数据库的属性，而一致性（在 ACID 意义上）是应用程序的属性。应用可能依赖数据库的原子性和隔离属性来实现一致性，但这并不仅取决于数据库。因此，字母 C 不属于 ACID 。



### ⭐MySQL有哪些事务隔离级别？

Mysql默认隔离级别：REPEATABLE-READ

Oracle默认隔离级别：READ-COMMITTED

MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。

- **READ-UNCOMMITTED(读取未提交)** ： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
- **READ-COMMITTED(读取已提交)** ： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
- **REPEATABLE-READ(可重复读)** ： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
- **SERIALIZABLE(可串行化)** ： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

------

|     隔离级别     | 脏读 | 不可重复读 | 幻读 |
| :--------------: | :--: | :--------: | :--: |
| READ-UNCOMMITTED |  √   |     √      |  √   |
|  READ-COMMITTED  |  ×   |     √      |  √   |
| REPEATABLE-READ  |  ×   |     ×      |  √   |
|   SERIALIZABLE   |  ×   |     ×      |  ×   |



### ⭐数据库索引失效有哪些？

[详细查看文章open in new window](https://xiaolincoding.com/mysql/index/index_lose.html)

![图片](https://cdn.xiaolincoding.com//mysql/other/a9e6a9708a6dbbcc65906d1338d2ae70.png)

- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对索引列使用函数，就会导致索引失效。
- 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。
- MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。



### ⭐数据库sql优化有哪些方法？

> 规范

[MySQL高性能优化规范建议open in new window](https://javaguide.cn/database/mysql/mysql-high-performance-optimization-specification-recommendations.html#数据库命令规范)

1. 尽量避免使用子查询
2. 用IN来替换OR
3. 读取适当的记录LIMIT M,N，而不要读多余的记录
4. 禁止不必要的Order By排序
5. 总和查询可以禁止排重用union all
6. 避免随机取记录
7. 将多次插入换成批量Insert插入
8. 只返回必要的列，用具体的字段列表代替 select * 语句
9. 区分in和exists
10. 优化Group By语句
11. 尽量使用数字型字段
12. 优化Join语句

> 步骤详细参考：[SQL语句优化](https://www.pdai.tech/md/db/sql-lan/sql-lan-optimize.html#sql语言---sql语句优化)



### ⭐️为什么MySQL底层要用B+树？

图解B+树：[https://zhuanlan.zhihu.com/p/54102723open in new window](https://zhuanlan.zhihu.com/p/54102723)

B 树也称 B-树,全称为 **多路平衡查找树** ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 `Balanced` （平衡）的意思。

目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。

**MySQL数据库底层选择使用B+树，而不是B树，主要有以下几个原因**：

- **范围查询的优化**：B+树的所有关键字数据都出现在叶子节点，所有数据记录都链在一起，因此对整个区间的数据能够进行快速地遍历，适合文件索引和数据库索引。而在B树中，数据分布在整个树中，如果进行范围查询，可能需要遍历整个树，效率较低。
- **查询效率的稳定性**：B+树的内部节点并不包含数据信息，只包含子节点的指针，这意呈现每个内部节点所能保存的子节点指针数量更多，树的高度较低，查询的效率更加稳定。而B树因为非叶子节点也可能包含数据，所以每个节点能保存的子节点指针数量较少，树的高度可能会增加，导致查询效率的波动。
- **磁盘I/O操作优化**：因为磁盘I/O操作相对于内存访问来说，代价要高得多，B+树的设计更加注重减少磁盘I/O次数。B+树每一个节点的子节点数量都较多，这意味着可以通过一次I/O取得更多的索引信息。

**B 树& B+树两者有何异同呢？**

- B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。
- B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
- B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

在 MySQL 中，MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是，两者的实现方式不太一样。

MyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后**以 data 域的值为地址读取相应的数据记录**。这被称为“**非聚簇索引**”。

InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，**树的叶节点 data 域保存了完整的数据记录**。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为**“聚簇索引（或聚集索引）**”，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

### 💥详解B+树？

B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树结构如下图：

![image-20220718133551150](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220718133551150-f5c9cbea.webp)image-20220718133551150

B+ 树与 B 树差异的点，主要是以下这几点：

- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
- 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。
- 非叶子节点中有多少个子节点，就有多少个索引；

下面通过三个方面，比较下 B+ 和 B 树的性能区别。

#### [#](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/Java/eightpart/mysql.html#b-树是如何进行查询的)B+ 树是如何进行查询的？

一个数据页中的记录检索，因为一个数据页中的记录是有限的，且主键值是有序的，所以通过对所有记录进行分组，然后将组号（槽号）存储到页目录，使其起到索引作用，通过二分查找的方法快速检索到记录在哪个分组，来降低检索的时间复杂度。

但是，当我们需要存储大量的记录时，就需要多个数据页，这时我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页。

为了解决这个问题，**InnoDB 采用了 B+ 树作为索引**。磁盘的 I/O 操作次数对索引的使用效率至关重要，因此在构造索引的时候，我们更倾向于采用“矮胖”的 B+ 树数据结构，这样所需要进行的磁盘 I/O 次数更少，而且 B+ 树 更适合进行关键字的范围查询。

InnoDB 里的 B+ 树中的**每个节点都是一个数据页**，结构示意图如下：

![image-20220718134312198](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220718133843334-a3cba1a2.webp)image-20220718134312198

通过上图，我们看出 B+ 树的特点：

- 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。
- 非叶子节点分为不同层次，通过分层来降低每一层的搜索量；
- 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；

我们再看看 B+ 树如何实现快速查找主键为 6 的记录，以上图为例子：

- 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项；
- 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录；
- 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。

可以看到，在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找。

#### [#](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/Java/eightpart/mysql.html#单点查询)单点查询

B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。

但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引。

**B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少**。

#### [#](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/Java/eightpart/mysql.html#插入和删除效率)插入和删除效率

B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，

比如下面这个动图是删除 B+ 树 0004 节点的过程，因为非叶子节点有 0004 的冗余节点，所以在删除的时候，树形结构变化很小：

![img](https://img-blog.csdnimg.cn/25508b0cd9c44ef6937fdd737020a7f1.gif)

> 注意，：B+ 树对于非叶子节点的子节点和索引的个数，定义方式可能会有不同，有的是说非叶子节点的子节点的个数为 M 阶，而索引的个数为 M-1（这个是维基百科里的定义），因此我本文关于 B+ 树的动图都是基于这个。但是我在前面介绍 B+ 树与 B+ 树的差异时，说的是「非叶子节点中有多少个子节点，就有多少个索引」，主要是 MySQL 用到的 B+ 树就是这个特性。

下面这个动图是删除 B 树 0008 节点的过程，可能会导致树的复杂变化：

![img](https://img-blog.csdnimg.cn/2be62679487640bbaac663fa96c7f35f.gif)

甚至，B+ 树在删除根节点的时候，由于存在冗余的节点，所以不会发生复杂的树的变形，比如下面这个动图是删除 B+ 树根节点的过程：

![img](https://img-blog.csdnimg.cn/23730b5af987480fabff0f1d142a2b6c.gif)

B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂，比如删除根节点中的数据，可能涉及复杂的树的变形，比如下面这个动图是删除 B 树根节点的过程：

![img](https://img-blog.csdnimg.cn/img_convert/7552002f9b8195ab650d431bfe66cce2.gif)

B+ 树的插入也是一样，有冗余节点，插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。而且 B+ 树会自动平衡，不需要像更多复杂的算法，类似红黑树的旋转操作等。

因此，**B+ 树的插入和删除效率更高**。

#### [#](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/Java/eightpart/mysql.html#范围查询)范围查询

B 树和 B+ 树等值查询原理基本一致，先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。

因为 **B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助**，比如说我们想知道 12 月 1 日和 12 月 12 日之间的订单，这个时候可以先查找到 12 月 1 日所在的叶子节点，然后利用链表向右遍历，直到找到 12 月12 日的节点，这样就不需要从根节点查询了，进一步节省查询需要的时间。

而 B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。

因此，存在大量范围检索的场景，适合使用 B+树，比如数据库。而对于大量的单个索引查询的场景，可以考虑 B 树，比如 nosql 的MongoDB

#### [#](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/Java/eightpart/mysql.html#mysql-中的-b-树)MySQL 中的 B+ 树

MySQL 的存储方式根据存储引擎的不同而不同，我们最常用的就是 Innodb 存储引擎，它就是采用了 B+ 树作为了索引的数据结构。

下图就是 Innodb 里的 B+ 树：

![image-20220718133843334](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220718133843334-a3cba1a2.webp)image-20220718133843334

但是 Innodb 使用的 B+ 树有一些特别的点，比如：

- B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。
- B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。

Innodb 根据索引类型不同，分为聚集和二级索引。他们区别在于，聚集索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚集索引的叶子节点，而二级索引的叶子节点存放的是主键值，而不是实际数据。

因为表的数据都是存放在聚集索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚集索引，且由于数据在物理上只会保存一份，所以聚簇索引只能有一个，而二级索引可以创建多个。

# Redis

### 介绍一下Redis？

简单来说 **Redis 就是一个使用 C 语言开发的数据库**，不过与传统数据库不同的是 **Redis 的数据是存在内存中的** ，也就是它是内存数据库，所以读写速度非常快，因此 Redis 被广泛应用于缓存方向。另外，**Redis 除了做缓存之外，也经常用来做分布式锁，甚至是消息队列。Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。**



### Redis为什么这么快？

- redis完全**基于内存**,绝大部分请求是纯粹的内存操作,非常快速.
- **数据结构简单**,对数据操作也简单,redis中的数据结构是专门进行设计的
- 采用**单线程模型**, 避免了不必要的上下文切换和竞争条件, 也不存在多线程或者多线程切换而消耗CPU, 不用考虑各种锁的问题, 不存在加锁, 释放锁的操作, 没有因为可能出现死锁而导致性能消耗
- 使用了**多路IO复用模型**,非阻塞IO
- 使用**底层模型不同**，Redis直接自己构建了 VM (虚拟内存)机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求



### ⭐为什么用 Redis / 为什么要缓存？

主要是因为 **Redis 具备「高性能」和「高并发」两种特性**。

主要从两个方面讲：

***1、Redis 具备高性能***

假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。

![image-20220714213332696](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714213332696-ba5b200e.webp)

如果 MySQL 中的对应数据改变的之后，同步改变 Redis 缓存中相应的数据即可，不过这里会有 Redis 和 MySQL 双写一致性的问题，后面我们会提到。

***2、 Redis 具备高并发***

单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。

所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。



### Redis 如何实现服务高可用？

要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。

> 主从复制

主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

![image-20220715161214356](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220158025-6447acd9.webp)

也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。

注意，主从服务器之间的命令复制是**异步**进行的。

具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。

所以，无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。

> 哨兵模式

在使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。

为了解决这个问题，Redis 增加了哨兵模式（**Redis Sentinel**），因为哨兵模式做到了可以监控主从服务器，并且提供**主从节点故障转移的功能。**

![image-20220715161234139](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220557761-5b3fc0f3.webp)image-20220715161234139

> 切片集群模式

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**（Redis Cluster ）方案，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：

- 根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
- 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：

- **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
- **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。

![image-20220715161306957](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220715161306957-d5056b8b.webp)image-20220715161306957

上图中的切片集群一共有 3 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。



```c
redis-cli -h 192.168.1.10 –p 6379 cluster addslots 0,1
redis-cli -h 192.168.1.11 –p 6379 cluster addslots 2,3
```

然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 5 进行取模，再根据各自的模数结果，就可以被映射到对应的节点 1 和节点 3 上了。

需要注意的是，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。



### Redis 除了做缓存，还能做什么？

**分布式锁** ： 通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。相关阅读：[《分布式锁中的王者方案 - Redisson》open in new window](https://mp.weixin.qq.com/s/CbnPRfvq4m1sqo2uKI6qQw)

**限流** ：一般是通过 Redis + Lua 脚本的方式来实现限流。相关阅读：[《我司用了 6 年的 Redis 分布式限流器，可以说是非常厉害了！》open in new window](https://mp.weixin.qq.com/s/kyFAWH3mVNJvurQDt4vchA)

**消息队列** ：Redis 自带的 list 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。

**复杂业务场景** ：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景比如通过 bitmap 统计活跃用户、通过 sorted set 维护排行榜。

......

### ⭐基本数据类型、应用场景

> 5种基本数据类型：string、list、hash、set、zset
>
> 推荐阅读：[图解 Redis 数据结构open in new window](https://mp.weixin.qq.com/s/qptE172slg_6Tl1yuzdbfw)

#### 1️⃣string

1. **介绍** ：string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 **简单动态字符串**（simple dynamic string，**SDS**）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。
2. **常用命令：** `set,get,strlen,exists,decr,incr,setex` 等等。
3. **应用场景：** 一般常用在需要**计数**的场景，比如用户的访问次数、热点文章的点赞转发数量；**缓存**，经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力；**session**，常见方案spring session + redis实现session共享等等。

#### 2️⃣list

1. **介绍** ：**list** 即是 **链表**。链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 **LinkedList**，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
2. **常用命令:** `rpush,lpop,lpush,rpop,lrange,llen` 等。
3. **应用场景:** 非常适合用于实现队列和栈，以及在特定范围内存储和获取元素，例如消息队列，用户的动态等。

#### 3️⃣hash

1. **介绍** ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。
2. **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。
3. **应用场景:** 存储和管理对象，比如存储用户的信息，比如用户名，密码，邮箱等。

#### 4️⃣set

1. **介绍 ：** set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。
2. **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。
3. **应用场景:** Set类型常常被用来处理一些需要快速查找的场景，比如社交网络中的好友关系，标签等。

#### 5️⃣Zset

1. **介绍 ：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。
2. **常用命令：** `ZADD 将一个带有给定分值的成员添加到有序集合里面,ZRANGE 根据元素在有序集合中所处的位置，从有序集合中获取多个元素,ZREM 如果给定元素成员存在于有序集合中，那么就移除这个元素` 等。
3. **应用场景:** **排行榜** 需要对数据根据某个权重进行排序的场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行；在直播系统中，实时排行信息包含直播间在线用户列表；各种礼物**排行榜**，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。
4. 有序集合是通过两种数据结构实现：

Redis在实现有序集合时针对不同的情况采用了不同的数据结构。当**有序集合中的元素数量比较多或者元素的字符串长度较长时，Redis会采用跳表**数据结构来实现有序集合，因为跳表可以提供较快的查找性能。而当有序集合中的**元素数量比较少或者元素的字符串长度较短时，Redis会采用压缩列表**数据结构来实现有序集合，因为压缩列表可以在占用较少内存的情况下存储元素。

1. **压缩列表(ziplist)**: ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关
2. **跳跃表（zSkiplist)**: 跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这是采用跳跃表的主要原因。跳跃表的复杂度是O(log(n))。

> 关于什么时候会用到跳表或者什么时候用到压缩列表官网有介绍：[https://redis.io/docs/management/optimization/memory-optimization/open in new window](https://redis.io/docs/management/optimization/memory-optimization/)
>
> - Redis中ziplist和zSkiplist有一个阈值，由两个配置参数决定：`zset-max-ziplist-entries`和`zset-max-ziplist-value`
> - 官网给的都不一样，假设使用的Redis7.2，这两个参数的默认值分别为128和64，这意味着如果一个排序集的元素超过128个或任何元素长度超过64字节，它将被转换为跳表
> - 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。

随着 Redis 版本的更新，后面又支持了四种数据类型：BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）

#### 特殊类型： bitmap

1. **介绍：** bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间。
2. **常用命令：** `setbit` 、`getbit` 、`bitcount`、`bitop`
3. **应用场景：** 适合需要保存状态信息（比如是否签到、是否登录...）并需要进一步对这些信息进行分析的场景。比如用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。

### ⭐ 持久化策略（RDB、AOF） / 怎么保证 Redis 挂掉之后再重启数据可以进行恢复

> 概述：
>
> RDB持久化是把当前进程数据生成快照保存到磁盘上的过程; 针对RDB不适合实时持久化的问题，Redis提供了AOF持久化方式来解决.
>
> AOF是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。
>
> Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照**的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作

很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，大部分原因是为了之后重用数据（比如重启机器、机器故障之后恢复数据），或者是为了防止系统故障而将数据备份到一个远程位置。

Redis 不同于 Memcached 的很重要一点就是，Redis 支持持久化，而且支持两种不同的持久化操作。**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**。

#### RDB 概述

Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。

Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

快照持久化是 Redis 默认采用的持久化方式，在 `redis.conf` 配置文件中默认有此下配置：



```bash
save 60 1000
```

则在60秒内如果有1000个key发生变化，就会触发一次RDB快照的执行

#### RDB 原理

Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程（执行 bgsave 命令的时候，会通过 `fork()` 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个）。子进程做数据持久化，不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。父进程则持续服务客户端请求，并对内存数据结构进行不间断的修改。这个时候就会使用操作系统的 COW（Copy-On-Write）机制来进行数据段页面的分离。

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/c34a9d1f58d602ff1fe8601f7270baa7-e68cd536.webp)

具体来说，当父进程对数据段中的一个页面进行修改时，被共享的页面会复制一份分离出来，然后对这个复制的页面进行修改，而子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，**内存就会持续增长，但不会超过原有数据内存的 2 倍大小**。

![当父进程对数据段中的一个页面进行修改](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/ebd620db8a1af66fbeb8f4d4ef6adc68-a764fa3d.webp)当父进程对数据段中的一个页面进行修改

另外，Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都被分离的情况，被分离的往往只有其中一部分页面。每个页面的大小只有 4KB，一个 Redis 实例里面一般都会有成千上万个页面。

子进程能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫“快照”的原因。接下来子进程就可以非常安心地遍历数据，进行序列化写磁盘了。

> ⚠️ 注意：bgsave 快照过程中，如果主线程修改了共享数据，**发生了写时复制后，RDB 快照保存的是原本的内存数据**，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。
>
> 所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据。
>
> 如果系统恰好在 RDB 快照文件创建完毕后崩溃了，那么 Redis 将会丢失主线程在快照期间修改的数据。
>
> 另外，写时复制的时候会出现这么个极端的情况。
>
> 在 Redis 执行 RDB 持久化期间，刚 fork 时，主进程和子进程共享同一物理内存，但是途中主进程处理了写操作，修改了共享内存，于是当前被修改的数据的物理内存就会被复制一份。

总结一下：

1. 在 RDB 快照生成过程中，Redis 主进程会执行 bgsave 命令，创建一个子进程来生成 RDB 文件。这个子进程会将 Redis 内存中的数据写入到磁盘中，生成一个快照文件。在生成快照文件期间，主进程可以继续处理客户端的请求（被修改），因为子进程是独立于主进程的。
2. 当主进程需要修改共享数据时，会使用写时复制技术COW，创建一个新的副本，以便主进程可以对副本进行修改，而不会影响子进程正在生成的快照文件中的原始数据。主进程对副本的修改不会影响子进程正在生成的快照文件中的原始数据，因为子进程只会将内存中的原始数据写入到磁盘中，而不会包括主进程对副本的修改。

> 参考：
>
> 1. [https://xiaolincoding.com/redis/storage/rdb.html#快照怎么用open in new window](https://xiaolincoding.com/redis/storage/rdb.html#快照怎么用) RDB 快照是怎么实现的？
> 2. 《redis深度历险》- 第二章 持久化

#### AOF 日志

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/6f0ab40396b7fc2c15e6f4487d3a0ad7-24b2d79e.webp) 这种保存写操作命令到日志的持久化方式，就是 Redis 里的 AOF(Append Only File) 持久化功能，注意只会记录写操作命令，读操作命令是不会被记录的，因为没意义。

在 Redis 中 AOF 持久化功能默认是不开启的，需要我们修改 redis.conf 配置文件中的以下参数：



```bash
// redis .conf
appendonly yes // 表示是否开启AOF持久化(默认 no，关闭):
“appendonly.aof” // AOF持久化文件的名称
appendfilename
```

AOF 日志文件其实就是普通的文本，我们可以通过 cat 命令查看里面的内容，不过里面的内容如果不知道一定的规则的话，可能会看不懂。

我这里以「set name xiaolin」命令作为例子，Redis 执行了这条命令后，记录在 AOF 日志里的内容如下图：

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/337021a153944fd0f964ca834e34d0f2-0d776db7.webp) 「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。

不知道大家注意到没有，Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。

第一个好处，**避免额外的检查开销。**

因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。

而如果先执行写操作命令再记录日志的话，只有在该命令执行成功后，才将命令记录到 AOF 日志里，这样就不用额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的。

第二个好处，**不会阻塞当前写操作命令的执行**，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。

当然，AOF 持久化功能也不是没有潜在风险。

第一个风险，执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有**丢失的风险**。

第二个风险，前面说道，由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是**可能会给「下一个」命令带来阻塞风险**。

因为将命令写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程），也就是说这两个操作是同步的。

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/28afd536c57a46447ddab0a2062abe84-3d5a5392.webp) 如果在将日志内容写入到硬盘时，服务器的硬盘的 I/O 压力太大，就会导致写硬盘的速度很慢，进而阻塞住了，也就会导致后续的命令无法执行。

认真分析一下，其实这两个风险都有一个共性，都跟「 AOF 日志写回硬盘的时机」有关。

#### 三种写回策略

AOF持久化最终需要将缓冲区中的内容写入一个文件，写文件通过操作系统提供的write函数执行。但是write之后数据只是保存在kernel的缓冲区中，真正写入磁盘还需要调用fsync函数。fsync是一个阻塞并且缓慢的操作，所以Redis通过appendfsync配置控制执行fsync的频次。具体有如下3种模式：

- **Always**，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- **Everysec**，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/98987d9417b2bab43087f45fc959d32a-22785b17.webp)

如果将AOF持久化策略设置为always（总是），你可以使用CONFIG SET命令。在Redis的命令行接口（CLI）中，输入以下命令：



```bash
CONFIG SET appendfsync always
```

这会立即更改Redis服务器的持久化策略。注意，这个配置会立即生效，但如果你重启Redis服务器，更改不会被保存。如果你想让这个配置在重启后仍然生效，你需要在Redis的配置文件(redis.conf)中进行修改。找到appendfsync这一行，修改为：



```bash
appendfsync always
```

然后重启Redis服务器，这个配置就会在启动时生效。

#### AOF 重写

AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。

如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。

所以，Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

举个例子，在没有使用重写机制前，假设前后执行了「set name xiaolin」和「set name xiaolincoding」这两个命令的话，就会将这两个命令记录到 AOF 文件。 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/723d6c580c05400b3841bc69566dd61b-35b598c7.webp)

但是在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。

重写工作完成后，就会将新的 AOF 文件覆盖现有的 AOF 文件，这就相当于压缩了 AOF 文件，使得 AOF 文件体积变小了。

然后，在通过 AOF 日志恢复数据时，只用执行这条命令，就可以直接完成这个键值对的写入了。

所以，重写机制的妙处在于，尽管某个键值对被多条写命令反复修改，最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量。最后在重写工作完成后，将新的 AOF 文件覆盖现有的 AOF 文件。

这里说一下为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去。

因为如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染，可能无法用于恢复使用。

所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响。

#### RDB和AOF抉择

**实现方式1**：RDB保存的是一个时间点的快照，那么如果Redis出现了故障，丢失的就是从最后一次RDB执行的时间点到故障发生的时间间隔之内产生的数据。如果Redis数据量很大，QPS很高，那么执行一次RDB需要的时间会相应增加，发生故障时丢失的数据也会增多。而AOF保存的是一条条命令，理论上可以做到发生故障时只丢失一条命令。

**实现方式2**：RDB保存的是最终的数据，是一个最终状态，而AOF保存的是达到这个最终状态的过程。很明显，如果Redis有大量的修改操作，RDB中一个数据的最终态可能会需要大量的命令才能达到，这会造成AOF文件过大并且加载时速度过慢

AOF和RDB文件的**加载过程**：RDB只需要把相应数据加载到内存并生成相应的数据结构（有些结构如intset、ziplist，保存时直接按字符串保存，所以加载时速度会更快），而AOF文件的加载需要先创建一个伪客户端，然后把命令一条条发送给Redis服务端，服务端再完整执行一遍相应的命令。根据Redis作者做的测试，RDB10s～20s能加载1GB的文件，AOF的速度是RDB速度的一半（如果做了AOF重写会加快）。

#### 混合持久化

尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握：

- 如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；
- 如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。 那有没有什么方法不仅有 RDB 恢复速度快的优点和，又有 AOF 丢失数据少的优点呢？

当然有，那就是将 RDB 和 AOF 合体使用，这个方法是在 Redis 4.0 提出的，该方法叫混合使用 AOF 日志和内存快照，也叫混合持久化。

如果想要开启混合持久化功能，可以在 Redis 配置文件将下面这个配置项设置成 yes：



```bash
aof-use-rdb-preamble yes
```

混合持久化工作在 AOF 日志重写过程。

当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/QQ%E6%88%AA%E5%9B%BE20230623223403-fb2adf7b.webp)

也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。

![image-20220715160726101](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220715160726101-40913c1a.webp)image-20220715160726101

这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。

加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。

> 参考：
>
> 1. Redis 5 设计与源码分析
> 2. [https://xiaolincoding.com/redis/storage/aof.html#aof-持久化是怎么实现的open in new window](https://xiaolincoding.com/redis/storage/aof.html#aof-持久化是怎么实现的)

### 🌟 缓存穿透 & 缓存雪崩 & 缓存击穿

> 概要：redis`缓存穿透`、缓存击穿和缓存雪崩都是Redis缓存中的问题。（面试问到直接这样答就完事了，如果问到更细节的问题可以看下面的内容）
>
> 1. 缓存穿透是指`查询一个不存在的数据`，由于缓存中没有，所以每次请求都会到数据库中查询，这样会对数据库造成很大的压力
>
> 2. `缓存击穿`是指一个key非常热点，在不停的`扛着大并发`，大量的请求同时访问这个key，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库
>
> 3. 而`缓存雪崩`是指`在某一个时间段，缓存集中过期失效`。这样，在失效的一瞬间，大量的请求直接打到数据库上，导致数据库短时间内承受巨大压力。
>
>    解决方案如下：
>
> - 对于缓存穿透问题，可以采用`布隆过滤器`或者将查询结果为空也写入缓存（使用RedisBloom模块实现布隆过滤器）
> - 对于缓存击穿问题，可以采用`互斥锁`或者使用`分布式锁`（使用`synchronized`关键字或`ReentrantLock`实现互斥锁、使用Redlock算法或基于ZooKeeper的分布式锁）
> - 对于缓存雪崩问题，可以采用`加过期时间随机值`或者使用`消息队列`来削峰填谷（常见的消息队列有RabbitMQ、Kafka等。）

#### 穿透

当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。

![image-20220714212317883](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714212317883-e9bc6127.webp)image-20220714212317883

缓存穿透的发生一般有这两种情况：

- 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

应对缓存穿透的方案，常见的方案有三种。

- **非法请求的限制**：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。
- **设置空值或者默认值**：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。
- **使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在**：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。

> 详细说明

**1）缓存无效 key**

如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： `SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。

**2）布隆过滤器**

布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。

具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

加入布隆过滤器之后的缓存处理流程图如下。

![image-20220616204045863](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220616204045863-71400146.webp)image-20220616204045863

但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： **布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

*为什么会出现误判的情况呢? 我们还要从布隆过滤器的原理来说！*

我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

然后，一定会出现这样一种情况：**不同的字符串可能哈希出来的位置相同。** （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）

更多关于布隆过滤器的内容可以看我的这篇原创：[《不了解布隆过滤器？一文给你整的明明白白！》open in new windowopen in new window](https://javaguide.cn/cs-basics/data-structure/bloom-filter/) ，强烈推荐，个人感觉网上应该找不到总结的这么明明白白的文章了

#### 【拓展1】布隆过滤器

什么是布隆过滤器？

首先，我们需要了解布隆过滤器的概念。

布隆过滤器（Bloom Filter）是一个叫做 Bloom 的老哥于 1970 年提出的。我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。

![布隆过滤器示意图](data:image/webp;base64,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)布隆过滤器示意图

位数组中的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1。这样申请一个 100w 个元素的位数组只占用 1000000Bit / 8 = 125000 Byte = 125000/1024 kb ≈ 122kb 的空间。

总结：**一个名叫 Bloom 的人提出了一种来检索元素是否在给定大集合中的数据结构，这种数据结构是高效且性能很好的，但缺点是具有一定的错误识别率和删除难度。并且，理论情况下，添加到集合中的元素越多，误报的可能性就越大。**

布隆过滤器的原理

**当一个元素加入布隆过滤器中的时候，会进行如下操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

举个简单的例子：

![布隆过滤器hash计算](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-hash%E8%BF%90%E7%AE%97-3fcd5a44.webp)布隆过滤器hash计算

如图所示，当字符串存储要加入到布隆过滤器中时，该字符串首先由多个哈希函数生成不同的哈希值，然后将对应的位数组的下标设置为 1（当位数组初始化时，所有位置均为 0）。当第二次存储相同字符串时，因为先前的对应位置已设置为 1，所以很容易知道此值已经存在（去重非常方便）。

如果我们需要判断某个字符串是否在布隆过滤器中时，只需要对给定字符串再次进行相同的哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

**不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数。**

综上，我们可以得出：**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在**

#### 【拓展2】布谷鸟过滤器（Cuckoo Filter）

##### 布谷鸟哈希

布谷鸟过滤器用更低的空间开销解决了布隆过滤器不能删除元素的问题，做到了更好的效果，具体的

- 支持动态的添加和删除元素
- 提供了比传统布隆过滤器更高的查找性能，即使在接近满的情况下（比如空间利用率达到 95% 的时候）
- 比起商过滤器它更容易实现
- 如果要求误判率低于3%，它比布隆过滤器有更低的空间开销

本质上来说它为解决哈希冲突提供了另一种策略，利用较少计算换取了较大空间。它具有占用空间小、查询迅速等特性。名称源于采取了一种和布谷鸟一样的养娃方法

> 布谷鸟交配后，雌性**布谷鸟**就准备产蛋了，但它却不会自己筑巢。它会来到像知更**鸟**、刺嘴莺等那些比它小的**鸟**类的巢中，移走原来的那窝蛋中的一个，用自己的蛋来取而代之。相对于它的体形来说，它的蛋是偏小的，而且蛋上的斑纹同它混入的其他**鸟**的蛋也非常相似，所以不易被分辨出来。如果不是这样，它的蛋肯定会被扔出去。

最原始的布谷鸟哈希方法是使用两个哈希函数对一个 `key`进行哈希，得到桶中的两个位置，此时

- 如果两个位置都为为空则将 `key`随机存入其中一个位置
- 如果只有一个位置为空则存入为空的位置
- 如果都不为空，则随机踢出一个元素，踢出的元素再重新计算哈希找到相应的位置

当然假如存在绝对的空间不足，那老是踢出也不是办法，所以一般会设置一个**踢出阈值**，如果在某次插入行为过程中连续踢出超过阈值，则进行扩容。

![image-20210727104910960](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/1617168-20210727195627534-1821849951-32c5b99a.webp)image-20210727104910960

##### 布谷鸟过滤器

![1](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/1617168-20210727195625561-1153589445-5fffa8c5.webp)1

上图（a）(b)展示了一个基本的布谷鸟哈希表的插入操作，是由一个桶数组组成，每个插入项都有由散列函数h1(x)和h2(x)确定的两个候选桶，具体操作上文中已经描述，此处不再赘述。

而基本的布谷鸟过滤器也是由两个或者多个哈希函数构成，布谷鸟过滤器的布谷鸟哈希表的基本单位称为**条目（entry）**。 每个条目存储一个**指纹（fingerprint）**，指纹指的是使用一个哈希函数生成的n位比特位，n的具体大小由所能接受的误判率来设置，论文中的例子使用的是8bits的指纹大小。

哈希表由一个桶数组组成，其中一个桶可以有多个条目（比如上述图c中有四个条目）。而每个桶中有四个指纹位置，意味着一次哈希计算后布谷鸟有四个“巢“可用，而且四个巢是连续位置，可以更好的利用cpu高速缓存。也就是说每个桶的大小是4*8bits

#### 雪崩

什么是缓存雪崩？

实际上，缓存雪崩描述的就是这样一个简单的场景：**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了

> 另一种说法是：
>
> 当**大量缓存数据在同一时间过期（失效）\**时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩**的问题。

![image-20220616203658271](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220616203658271-c92ba822.webp)image-20220616203658271

通常，我们会使用缓存用于缓冲对 DB 的冲击，如果缓存宕机，所有请求将直接打在 DB，造成 DB 宕机——从而导致整个系统宕机。

![image-20220616203727609](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220616203727609-e301538e.webp)image-20220616203727609

**2 种策略：**

- **将缓存失效时间随机打散：** 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率。
- **设置缓存不过期：** 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题。

#### 击穿

**缓存击穿**是指某一个热点数据缓存中没有但数据库中有数据（一般是缓存时间到期，比如秒杀活动，这类被频地访问的数据被称为热点数据）。这时由于并发用户特别多，同时读缓存没读到数据（**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取），就去数据库去取数据，引起数据库压力瞬间增大，被高并发的请求冲垮，这就是**缓存击穿**的问题。

解决：

1. **设置热点数据永远不过期**。
2. **接口限流与熔断**，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。
3. **设置互斥锁**。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。（可以使用 Redis 分布式锁）

![image-20220714212532910](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714212532910-e58aa144.webp)image-20220714212532910

> redis中缓存击穿的概念是扛着大量的并发突然失效导致并发打在数据库上，和雪崩有什么区别？
>
> 它们的定义和区别如下：
>
> - **缓存击穿（Cache penetration）**: 这种情况通常发生在大量并发请求针对一个已过期或不存在的缓存key时，这些请求会直接打到数据库上，可能会对数据库造成较大的压力。这种情况的“失效”通常指的是一个特定的key已经过期或者不存在。
> - **缓存雪崩（Cache avalanche）**: 缓存雪崩是指在一个很短的时间内，大量的缓存项同时过期。这样，大量的请求将直接打到数据库上，可能会导致数据库过载甚至崩溃。这通常发生在大量缓存数据的过期时间设置得过于集中，或者因系统故障导致的全局缓存失效。
>
> 两者的主要区别在于：缓存击穿通常是由一个特定的热点key引发的，而缓存雪崩则是由大量的key同时过期引发的。
>
> 解决这两种问题的方法也有所不同。缓存击穿可以通过设置热点数据永不过期，或者使用互斥锁等方式控制并发访问来防止；而缓存雪崩则可以通过设置不同的过期时间，或者使用备份缓存等方式来防止。

### ⭐Redis 如何实现延迟队列？

延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：

- 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
- 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；
- 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单； 在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。

使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97-7cff192c.webp)

### 主从复制方案是怎么做的？

![image-20220714220149168](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220149168-63cfd520.webp)image-20220714220149168

多台服务器要保存同一份数据，这里问题就来了。

这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？

Redis 提供了**主从复制模式**，来避免上述的问题。

这个模式可以保证多台服务器的数据一致性，且主从服务器之间采用的是「读写分离」的方式。

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

![image-20220714220158025](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220158025-6447acd9.webp)image-20220714220158025

也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。

同步这两个字说的简单，但是这个同步过程并没有想象中那么简单，要考虑的事情不是一两个。

我们先来看看，主从服务器间的第一次同步是如何工作的？

#### 第一次同步

多台服务器之间要通过什么方式来确定谁是主服务器，或者谁是从服务器呢？

我们可以使用 `replicaof`（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系。

比如，现在有服务器 A 和 服务器 B，我们在服务器 B 上执行下面这条命令：



```text
# 服务器 B 执行这条命令
replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
```

接着，服务器 B 就会变成服务器 A 的「从服务器」，然后与主服务器进行第一次同步。

主从服务器间的第一次同步的过程可分为三个阶段：

- 第一阶段是建立链接、协商同步；
- 第二阶段是主服务器同步数据给从服务器；
- 第三阶段是主服务器发送新写操作命令给从服务器。

为了让你更清楚了解这三个阶段，我画了一张图。

![image-20220714220220342](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220220342-67b0e667.webp)image-20220714220220342

> 接下来，我在具体介绍每一个阶段都做了什么。

*第一阶段：建立链接、协商同步*

执行了 replicaof 命令后，从服务器就会给主服务器发送 `psync` 命令，表示要进行数据同步。

psync 命令包含两个参数，分别是**主服务器的 runID** 和**复制进度 offset**。

- runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 "?"。
- offset，表示复制的进度，第一次同步时，其值为 -1。

主服务器收到 psync 命令后，会用 `FULLRESYNC` 作为响应命令返回给对方。

并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。

FULLRESYNC 响应命令的意图是采用**全量复制**的方式，也就是主服务器会把所有的数据都同步给从服务器。

所以，第一阶段的工作时为了全量复制做准备。

那具体怎么全量同步呀呢？我们可以往下看第二阶段。

*第二阶段：主服务器同步数据给从服务器*

接着，主服务器会执行 `bgsave` 命令来生成 RDB 文件，然后把文件发送给从服务器。

从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。

这里有一点要注意，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。

但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。那么为了保证主从服务器的数据一致性，**主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里。**

- 主服务器生成 RDB 文件期间；
- 主服务器发送 RDB 文件给从服务器期间；
- 「从服务器」加载 RDB 文件期间；

*第三阶段：主服务器发送新写操作命令给从服务器*

在主服务器生成的 RDB 文件发送完，从服务器加载完 RDB 文件后，然后将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，然后「从服务器」重新执行这些操作，至此主从服务器的数据就一致了。

至此，主从服务器的第一次同步的工作就完成了。

#### 命令传播

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。

![image-20220714220259046](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220259046-e63bf1b8.webp)image-20220714220259046

后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

上面的这个过程被称为**基于长连接的命令传播**，通过这种方式来保证第一次同步后的主从服务器的数据一致性。



### ⭐Sentinel（哨兵）

> Redis Sentinel，即Redis哨兵，在Redis 2.8版本开始引入。哨兵的核心功能是主节点的自动故障转移。

下图是一个典型的哨兵集群监控的逻辑图：

![image-20220617154744863](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220617154744863-2398ff13.webp)image-20220617154744863

哨兵实现了什么功能呢？下面是Redis官方文档的描述：

- **监控（Monitoring）**：哨兵会不断地检查主节点和从节点是否运作正常。
- **自动故障转移（Automatic failover）**：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。
- **配置提供者（Configuration provider）**：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。
- **通知（Notification）**：哨兵可以将故障转移的结果发送给客户端。

其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。

在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。

![image-20220714220520655](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220520655-2651ad24.webp)image-20220714220520655

这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。

这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了 ，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！

Redis 在 2.8 版本以后提供的**哨兵（\*Sentinel\*）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

#### 哨兵机制是如何工作的？

哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。

当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。

哨兵节点主要负责三件事情：**监控、选主、通知**。

![image-20220714220539777](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220539777-e079d697.webp)image-20220714220539777

所以，我们重点要学习这三件事情：

- 哨兵节点是如何监控节点的？又是如何判断主节点是否真的故障了？
- 根据什么规则选择一个从节点切换为主节点？
- 怎么把新主节点的相关信息通知给从节点和客户端呢？

#### 如何判断主节点真的故障了？

哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。

![image-20220714220557761](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220557761-5b3fc0f3.webp)image-20220714220557761

如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。这个「规定的时间」是配置项 `down-after-milliseconds` 参数设定的，单位是毫秒。

> 主观下线？难道还有客观下线？

是的没错，客观下线只适用于主节点。

之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。

所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**（*最少需要三台机器来部署哨兵集群*），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

具体是怎么判定主节点为「客观下线」的呢？

当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

![image-20220714220606567](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220606567-9c3aafe8.webp)image-20220714220606567

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。

PS：quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。

哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。

#### 由哪个哨兵进行主从故障转移？

前面说过，为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以**哨兵是以哨兵集群的方式存在的**。

问题来了，由哨兵集群中的哪个节点进行主从故障转移呢？

所以这时候，还需要在哨兵集群中选出一个 leeder，让 leeder 来执行主从切换。

选举 leeder 的过程其实是一个投票的过程，在投票开始前，肯定得有个「候选者」。

> 那谁来作为候选者呢？

哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。

举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。

![image-20220714220628098](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714220628098-a3a11324.webp)image-20220714220628098

当哨兵 B 收到赞成票数达到哨兵配置文件中的 quorum 配置项设定的值后，就会将主节点标记为「客观下线」，此时的哨兵 B 就是一个Leader 候选者。

> 候选者如何选举成为 Leader？

候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。

每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

那么在投票过程中，任何一个「候选者」，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。

这时候有的同学就会问了，如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？

每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。

> 为什么哨兵节点至少要有 3 个？

如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。

所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。

因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。

当然，你要问，如果 3 个哨兵节点，挂了 2 个怎么办？这个时候得人为介入了，或者增加多一点哨兵节点。

再说一个问题，Redis 1 主 4 从，5 个哨兵 ，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？

- **哨兵集群可以判定主节点“客观下线”**。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。
- **哨兵集群可以完成主从切换**。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件， 所以就能选举成功，因此哨兵集群可以完成主从切换。

如果 quorum 设置为 2 ，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。

如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。

可以看到，quorum 为 2 的时候，并且如果有 3 个哨兵故障的话，虽然可以判定主节点为“客观下线”，但是不能完成主从切换，这样感觉「判定主节点为客观下线」这件事情白做了一样，既然这样，还不如不要做，quorum 为 3 的时候，就可以避免这种无用功。

所以，**quorum 的值建议设置为哨兵个数的二分之一加1**，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且**哨兵节点的数量应该是奇数**。

#### 主从故障转移的过程是怎样的？

在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移的过程了，如下图：

![image-20220714222351206](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714222351206-94692510.webp)image-20220714222351206

主从故障转移操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

> 这块具体还是看[https://xiaolincoding.com/redis/cluster/sentinel.html#步骤一-选出新主节点open in new window](https://xiaolincoding.com/redis/cluster/sentinel.html#步骤一-选出新主节点)

#### 哨兵集群是如何组成的？

前面提到了 Redis 的发布者/订阅者机制，那就不得不提一下哨兵集群的组成方式，因为它也用到了这个技术。

在我第一次搭建哨兵集群的时候，当时觉得很诧异。因为在配置哨兵的信息时，竟然只需要填下面这几个参数，设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。



```c
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

不需要填其他哨兵节点的信息，我就好奇它们是如何感知对方的，又是如何组成哨兵集群的？

后面才了解到，**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。

在主从集群中，主节点上有一个名为 `__sentinel__:hello`的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到 `__sentinel__:hello` 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。

![image-20220714222643304](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714222643304-584f9ce3.webp)image-20220714222643304

通过这个方式，哨兵 B 和 C 也可以建立网络连接，这样一来，哨兵集群就形成了。

> 哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？

主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。

如下图所示，哨兵 B 给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵 A 和 C 可以通过相同的方法和从节点建立连接。![image-20220714222836699](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714222836699-a638d802.webp)

正式通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。

#### 总结

Redis 在 2.8 版本以后提供的**哨兵（\*Sentinel\*）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：**监控、选主、通知**。

哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。

*1、第一轮投票：判断主节点下线*

当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。

*2、第二轮投票：选出哨兵leader*

某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

*3、由哨兵 leader 进行主从故障转移*

选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则：
  - 过滤掉已经离线的从节点；
  - 过滤掉历史网络连接状态不好的从节点；
  - 将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

### ⭐高并发场景下，到底先更新缓存还是先更新数据库？

#### Cache aside

`Cache aside`也就是旁路缓存，是比较常用的缓存策略。 （1）读请求常见流程 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f3230323-ad034504.webp) 应用首先会判断缓存是否有该数据，缓存命中直接返回数据，缓存未命中即缓存穿透到数据库，从数据库查询数据然后回写到缓存中，最后返回数据给客户端。 （2）写请求常见流程 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303231303-95b2e619.webp)

首先更新数据库，然后从缓存中删除该数据。 看了写请求的图之后，有些同学可能要问了：为什么要删除缓存，直接更新不就行了？这里涉及到几个坑，我们一步一步踩下去。

#### Cache aside踩坑

Cache aside策略如果用错就会遇到深坑，下面我们来逐个踩。

##### 踩坑一：先更新数据库 再更新缓存

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303233-c40f4947.webp) 

如果同时有两个写请求需要更新数据，每个写请求都先更新数据库再更新缓存，在并发场景可能会出现数据不一致的情况。

如上图的执行过程：

（1）写请求1更新数据库，将 age 字段更新为18；

（2）写请求2更新数据库，将 age 字段更新为20；

（3）写请求2更新缓存，缓存 age 设置为20；

（4）写请求1更新缓存，缓存 age 设置为18；

执行完预期结果是数据库 age 为20，缓存 age 为20，结果缓存 age为18，这就造成了缓存数据不是最新的，出现了脏数据。

##### 踩坑二：先删缓存 再更新数据库

如果写请求的处理流程是先删缓存再更新数据库，在一个读请求和一个写请求并发场景下可能会出现数据不一致情况。 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303234-3e82458f.webp) 

如上图的执行过程：

（1）写请求删除缓存数据；

（2）读请求查询缓存未击中(Hit Miss)，紧接着查询数据库，将返回的数据回写到缓存中；

（3）写请求更新数据库。

整个流程下来发现数据库中age为20，缓存中age为18，缓存和数据库数据不一致，缓存出现了脏数据。

##### 踩坑三：先更新数据库 再删除缓存

在实际的系统中针对写请求还是推荐先更新数据库再删除缓存，但是在理论上还是存在问题，以下面这个例子说明。 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303232-9804a207.webp) 

如上图的执行过程：

（1）读请求先查询缓存，缓存未击中，查询数据库返回数据；

（2）写请求更新数据库，删除缓存；

（3）读请求回写缓存；

整个流程操作下来发现数据库age为20，缓存age为18，即数据库与缓存不一致，导致应用程序从缓存中读到的数据都为旧数据。

但我们仔细想一下，上述问题发生的概率其实非常低，因为通常数据库更新操作比内存操作耗时多出几个数量级，上图中最后一步回写缓存（set age 18）速度非常快，通常会在更新数据库之前完成。

如果这种极端场景出现了怎么办？我们得想一个兜底的办法：缓存数据设置过期时间。通常在系统中是可以允许少量的数据短时间不一致的场景出现。

#### Read through

在 Cache Aside 更新模式中，应用代码需要维护两个数据源头：一个是缓存，一个是数据库。而在 Read-Through 策略下，应用程序无需管理缓存和数据库，只需要将数据库的同步委托给缓存提供程序 Cache Provider 即可。所有数据交互都是通过抽象缓存层完成的。 ![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303231-8a030d4f.webp) 如上图，应用程序只需要与Cache Provider交互，不用关心是从缓存取还是数据库。

在进行大量读取时，Read-Through 可以减少数据源上的负载，也对缓存服务的故障具备一定的弹性。如果缓存服务挂了，则缓存提供程序仍然可以通过直接转到数据源来进行操作。

Read-Through 适用于多次请求相同数据的场景，这与 Cache-Aside 策略非常相似，但是二者还是存在一些差别，这里再次强调一下：

在 Cache-Aside 中，应用程序负责从数据源中获取数据并更新到缓存。 在 Read-Through 中，此逻辑通常是由独立的缓存提供程序（Cache Provider）支持。

#### Write-Through

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303235-a7af1475.webp) Write-Through 策略下，当发生数据更新(Write)时，缓存提供程序 Cache Provider 负责更新底层数据源和缓存。

缓存与数据源保持一致，并且写入时始终通过抽象缓存层到达数据源。

Cache Provider类似一个代理的作用。

#### Write behind

![img](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f736d696c654172636869746563742f617373657473406d61696e2f3230323130312f32303236-6794df52.webp) Write behind在一些地方也被成为Write back， 简单理解就是：应用程序更新数据时只更新缓存， Cache Provider每隔一段时间将数据刷新到数据库中。说白了就是延迟写入。

如上图，应用程序更新两个数据，Cache Provider 会立即写入缓存中，但是隔一段时间才会批量写入数据库中。

这种方式有优点也有缺点：

- 优点是数据写入速度非常快，适用于频繁写的场景。
- 缺点是缓存和数据库不是强一致性，对一致性要求高的系统慎用。

#### 缓存更新的策略:

缓存更新的策略主要分为三种：

- Cache aside
- Read/Write through
- Write behind Cache aside 通常会先更新数据库，然后再删除缓存，为了兜底通常还会将数据设置缓存时间。

Read/Write through 一般是由一个 Cache Provider 对外提供读写操作，应用程序不用感知操作的是缓存还是数据库。

Write behind简单理解就是延迟写入，Cache Provider 每隔一段时间会批量输入数据库，优点是应用程序写入速度非常快。

### ⭐MySQL 和 Redis 怎么保持数据一致?

对于缓存和数据库的操作，主要有以下两种方式。

#### 先删缓存，再更新数据库

举个 🌰 假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。

![image-20220715152802050](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220714102354617-3a3eef57.webp)image-20220715152802050

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。

可以看到，**先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题**。

> 核心理解：
>
> 用户A购买了一件商品，我们需要更新库存。这个过程如下：
>
> 1. 删除Redis中的库存缓存。
> 2. 更新MySQL中的库存数据。
>
> 问题是，在这两步操作之间，如果用户B查询了库存，他会发现Redis中没有缓存，因此他会从MySQL数据库读取库存数据（此时还未更新），并将旧的库存数据存入Redis。然后用户A的购买操作完成，MySQL的库存数据更新，但Redis中的数据仍是旧的，因此用户B看到的库存信息是错误的。
>
> 使用分布式锁可以解决这个问题。当用户A购买商品时，他首先获取商品库存的锁，然后删除Redis的缓存，更新MySQL的数据，最后释放锁。在此期间，如果用户B查询库存，他需要等待用户A释放锁。这样用户B总是能获得最新的库存信息。

##### 解决方案:延时双删

流程如下：

1. 线程1删除缓存，然后去更新数据库
2. 线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存
3. 线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除
4. 如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值

![image-20220715152925965](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220715152925965-d66057ab.webp)image-20220715152925965

> 核心理解：
>
> "延迟双删"是一种解决Redis缓存和MySQL数据库一致性问题的策略，这个策略的基本思想是在更新数据库之后和删除缓存之后都执行一个小的延迟操作。下面是"延迟双删"策略的具体步骤：
>
> 1. 删除Redis缓存。
> 2. 更新MySQL数据库。
> 3. 延迟一段时间（比如几十毫秒）。
> 4. 再次删除Redis缓存。
>
> 这种策略的关键在于，第3步的延迟时间需要足够长，以确保在这段时间内任何其他可能从MySQL读取旧数据并写入Redis缓存的操作都已经完成。这样，当执行第4步的时候，我们可以确保删除的是最新的缓存数据。
>
> 在这种情况下，即使在步骤1和步骤2之间有其他请求从MySQL读取了旧数据并写入Redis，由于我们在步骤4中再次删除了缓存，所以这样的旧数据也会被删除，不会出现数据不一致的问题。
>
> 需要注意的是，"延迟双删"策略并不能完全保证数据的一致性，比如在步骤3的延迟期间，如果有新的请求更新了数据库并更新了缓存，然后步骤4的删除操作可能会把这个新的缓存数据也删除了，导致数据不一致的问题。但在实际应用中，由于我们可以通过控制延迟时间来极大地减小这种情况发生的概率，所以"延迟双删"策略通常是一个有效的解决方案。

#### 先更新数据库，再删除缓存

继续用「读 + 写」请求的并发的场景来分析。

假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。![image-20220715152956657](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220715152956657-fee88181.webp)

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。

从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，**但是在实际中，这个问题出现的概率并不高**。

**因为缓存的写入通常要远远快于数据库的写入**，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。

而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。

所以，**「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的**。

> 核心理解：
>
> 用户A购买了一件商品，我们需要更新库存。这个过程如下：
>
> 1. 更新MySQL中的库存数据。
> 2. 删除Redis中的库存缓存。
>
> 问题是，在这两步操作之间，如果用户B查询了库存，他可能从Redis中读到了旧的库存数量（因为缓存还未删除）。然后即使MySQL的库存数据更新了，用户B看到的库存信息仍是旧的。

##### 解决方案1:消息队列

这是网上很多文章里都有写过的方案。但是这个方案的缺陷会更明显一点。

先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。

![image-20220715153053443](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220715153053443-a9510d0f.webp)image-20220715153053443

这个解决方案其实问题更多。

1. 引入消息中间件之后，问题更复杂了，怎么保证消息不丢失更麻烦
2. 就算更新数据库和删除缓存都没有发生问题，消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的

##### 解决方案2:进阶版消息队列

为了解决缓存一致性的问题单独引入一个消息队列，太复杂了。

其实，一般大公司本身都会有监听binlog消息的消息队列存在，主要是为了做一些核对的工作。

这样，我们可以借助监听binlog的消息队列来做删除缓存的操作。这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。

当然，这样消息延迟的问题依然存在，但是相比单纯引入消息队列的做法更好一点。

而且，如果并发不是特别高的话，这种做法的实时性和一致性都还算可以接受的。

![image-20220715153124553](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220715153124553-88e314dc.webp)image-20220715153124553

##### 解决方案3:设置缓存过期时间

每次放入缓存的时候，设置一个过期时间，比如5分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。

如果对于一致性要求不是很高的情况，可以采用这种方案。

这个方案还会有另外一个问题，就是如果数据更新的特别频繁，不一致性的问题就很大了。

在实际生产中，我们有一些活动的缓存数据是使用这种方式处理的。

因为活动并不频繁发生改变，而且对于活动来说，短暂的不一致性并不会有什么大的问题。

详细问题可以看：[数据库和缓存如何保证一致性？open in new window](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#先更新数据库-还是先删除缓存)

### ⭐️Redis如何实现分布式锁？

**分布式锁**：当多个进程不在同一个系统中(比如分布式系统中控制共享资源访问)，用分布式锁控制多个进程对资源的访问。

[Redis的官网open in new window](https://redis.io/docs/reference/patterns/distributed-locks/)上对使用分布式锁提出至少需要满足如下三个要求：

1. **互斥**（属于安全性）：在任何给定时刻，只有一个客户端可以持有锁。
2. **无死锁**（属于有效性）：即使锁定资源的客户端崩溃或被分区，也总是可以获得锁；通常通过超时机制实现。
3. **容错性**（属于有效性）：只要大多数 Redis 节点都启动，客户端就可以获取和释放锁。

**基于 redis 实现分布式锁**:

- 单个Redis实例：setnx(key,当前时间+过期时间) + Lua
- Redis集群模式：Redlock

#### 最简化版本

首先，当然是搭建一个最简单的实现方式，直接用Redis的setnx命令，这个命令的语法是：**setnx key value**

如果key不存在，则会将key设置为value，并返回1；如果key存在，不会有任务影响，返回0。

基于这个特性，我们就可以用setnx实现加锁的目的：通过setnx加锁，加锁之后其他服务无法加锁，用完之后，再通过delete解锁，深藏功与名

![image-20220709164349575](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164349575-bd46a2fc.webp)image-20220709164349575

#### 支持过期时间

最简化版本有一个问题：**如果获取锁的服务挂掉了，那么锁就一直得不到释放**，就像石沉大海，杳无音信。所以，我们需要一个超时来兜底。

Redis中有expire命令，用来设置一个key的超时时间。但是setnx和expire不具备原子性，如果setnx获取锁之后，服务挂掉，依旧是泥牛入海。

很自然，我们会想到，set和expire，有没有原子操作？

当然有，Redis早就考虑到了这种场景，推出了如下执行语句：**set key value nx ex seconds**

nx表示具备setnx特定，ex表示增加了过期时间，最后一个参数就是过期时间的值。

![image-20220709164418917](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164418917-02227db4.webp)image-20220709164418917

能够支持过期时间，目前这个锁基本上是能用了。

但是存在一个问题：会存在服务A释放掉服务B的锁的可能。

#### 加上owner

我们来试想一下如下场景：服务A获取了锁，由于业务流程比较长，或者网络延迟、GC卡顿等原因，导致锁过期，而业务还会继续进行。这时候，业务B已经拿到了锁，准备去执行，这个时候服务A恢复过来并做完了业务，就会释放锁，而B却还在继续执行。

在真实的分布式场景中，可能存在几十个竞争者，那么上述情况发生概率就很高，导致同一份资源频繁被不同竞争者同时访问，分布式锁也就失去了意义。

基于这个场景，我们可以发现，问题关键在于，竞争者可以释放其他人的锁。那么在异常情况下，就会出现问题，所以我们可以进一步给出解决方案：**分布式锁需要满足谁申请谁释放原则，不能释放别人的锁，也就是说，分布式锁，是要有归属的**

![image-20220709164452895](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164452895-c06ba80f.webp)image-20220709164452895

#### 引入Lua

加入owner后的版本可以称得上是完善了吗？还有没有什么隐患呢？

我也不卖关子了，到这一步其实还存在一个小问题，我们完整的流程是竞争者获取锁执行任务，执行完毕后检查锁是不是自己的，最后进行释放。

流程一梳理，你们肯定明白了，执行完毕后，**检查锁，再释放，这些操作不是原子化的。**

**可能锁获取时还是自己的，删除时却已经是别人的**了。这可怎么办呢？

Redis可没有直接提供这种场景原子化的操作啊。遇事不要慌，仔细想一想，Redis是不是还有个特性，专门整合原子操作，对，就是它——**Lua**

Redis➕Lua，可以说是专门为解决原子问题而生。

有了Lua的特性，Redis才真正在分布式锁、秒杀等场景，有了用武之地，下面便是改造之后的流程：

![image-20220709164528516](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164528516-06c9603b.webp)image-20220709164528516

其实到了这一步，分布式锁的前三个特性：对称性、安全性、可靠性，就满足了。可以说是一个可用的分布式锁了，能满足大多数场景的需要

#### Redisson

对于可能存在**锁过期释放，业务没执行完** 的问题。我们可以稍微把锁过期时间设置长一些，大于正常业务处理时间就好啦。如果你觉得不是很稳，还可以给获得锁的线程，开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁的过期时间延长，防止锁过期提前释放。

当前开源框架Redisson解决了这个问题。可以看下Redisson底层原理图：

![image-20220709164742280](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164742280-898caed3.webp)image-20220709164742280

只要线程一加锁成功，就会启动一个 `watch dog`看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用watch dog解决了**「锁过期释放，业务没执行完」**问题。

#### Redlock+Redisson

其实Redis一般都是集群部署的：

![image-20220709164811068](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164811068-b22010ec.webp)image-20220709164811068

如果线程一在Redis的master节点上拿到了锁，但是加锁的key还没同步到slave节点。恰好这时，master节点发生故障，一个slave节点就会升级为master节点。线程二就可以获取同个key的锁啦，但线程一也已经拿到锁了，锁的安全性就没了。

为了解决这个问题，Redis作者 antirez提出一种高级的分布式锁算法：Redlock。Redlock核心思想是这样的：

> ❝
>
> 搞多个Redis master部署，以保证它们不会同时宕掉。并且这些master节点是完全相互独立的，相互之间不存在数据同步。同时，需要确保在这多个master实例上，是与在Redis单实例，使用相同方法来获取和释放锁。
>
> ❞

我们假设当前有5个Redis master节点，在5台服务器上面运行这些Redis实例。

![image-20220709164830756](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220709164830756-d1a1a1f8.webp)image-20220709164830756

RedLock的实现步骤:如下

> ❝
>
> - 1.获取当前时间，以毫秒为单位。
> - 2.按顺序向5个master节点请求加锁。客户端设置网络连接和响应超时时间，并且超时时间要小于锁的失效时间。（假设锁自动失效时间为10秒，则超时时间一般在5-50毫秒之间,我们就假设超时时间是50ms吧）。如果超时，跳过该master节点，尽快去尝试下一个master节点。
> - 3.客户端使用当前时间减去开始获取锁时间（即步骤1记录的时间），得到获取锁使用的时间。当且仅当超过一半（N/2+1，这里是5/2+1=3个节点）的Redis master节点都获得锁，并且使用的时间小于锁失效时间时，锁才算获取成功。（如上图，10s> 30ms+40ms+50ms+4m0s+50ms）
> - 如果取到了锁，key的真正有效时间就变啦，需要减去获取锁所使用的时间。
> - 如果获取锁失败（没有在至少N/2+1个master实例取到锁，有或者获取锁时间已经超过了有效时间），客户端要在所有的master节点上解锁（即便有些master节点根本就没有加锁成功，也需要解锁，以防止有些漏网之鱼）。
>
> ❞

简化下步骤就是：

- 按顺序向5个master节点请求加锁
- 根据设置的超时时间来判断，是不是要跳过该master节点。
- 如果大于等于3个节点加锁成功，并且使用的时间小于锁的有效期，即可认定加锁成功啦。
- 如果获取锁失败，解锁！

#### Zookeeper分布式锁

Zookeeper的节点Znode有四种类型：

- **持久节点** ：默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在。
- **持久节点顺序节点** ：所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号，持久节点顺序节点就是有顺序的持久节点。
- **临时节点** ：和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。
- **临时顺序节点** ：有顺序的临时节点。

Zookeeper分布式锁实现应用了**临时顺序节点** 。这里不贴代码啦，来讲下zk分布式锁的实现原理吧。

##### zk获取锁过程

当第一个客户端请求过来时，Zookeeper客户端会创建一个持久节点`locks`。如果它（Client1）想获得锁，需要在`locks`节点下创建一个顺序节点`lock1`.如图

![image-20220725154831233](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220725154831233-3daebe34.webp)image-20220725154831233

接着，客户端Client1会查找`locks`下面的所有临时顺序子节点，判断自己的节点`lock1`是不是排序最小的那一个，如果是，则成功获得锁。

![image-20220725154850768](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220725154850768-0286274a.webp)image-20220725154850768

这时候如果又来一个客户端client2前来尝试获得锁，它会在locks下再创建一个临时节点`lock2`

![image-20220725154905321](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220725154905321-d37c21d3.webp)image-20220725154905321

客户端client2一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock2是不是最小的，此时，发现lock1才是最小的，于是获取锁失败。获取锁失败，它是不会甘心的，client2向它排序靠前的节点lock1注册Watcher事件，用来监听lock1是否存在，也就是说client2抢锁失败进入等待状态。

![image-20220725154920071](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220725154920071-e8ac43fe.webp)image-20220725154920071

此时，如果再来一个客户端Client3来尝试获取锁，它会在locks下再创建一个临时节点lock3

![image-20220725154933777](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220725154933777-9304ed48.webp)image-20220725154933777

同样的，client3一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock3是不是最小的，发现自己不是最小的，就获取锁失败。它也是不会甘心的，它会向在它前面的节点lock2注册Watcher事件，以监听lock2节点是否存在。

![image-20220725154939637](https://zhiyu1998.github.io/Computer-Science-Learn-Notes/assets/image-20220725154939637-98e4b9ac.webp)image-20220725154939637
